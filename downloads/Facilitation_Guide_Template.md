# TITLE

## Revision History

### Version 2.0 (date)

Summary of major changes, and who made them.

### Version 1.1 (date)

Summary of minor changes, and who made them.

### Version 1.0 (date)

Initial version. List main authors.


## Table of Contents

## Background or Introduction to Course/Program
### What is the Purpose or Goal?

> The goal of this section of a local Guide is to orient new instructors to the course or program __overall__. _Specifics come later.


### Summary of Initial Analysis Data

> Always document the initial analysis, so you have a point of comparison in the future. Focus on where students are now:_

> * What do students know already, not know?
> * What motivation or affect issues are you concerned about?


### General Learning Outcomes, Performance Benchmarks

> Include what an average student can do when entering the course or program, and what the outcome goals are by the end.


### Why Cases Are Being Used

> It is easy to forget why we use cases instead of another active learning modality. Providing the rationale for using cases also can increase new instructor buy-in.


## Course Mechanics

> The subsections here should address the most common logistical questions that new instructors might have about course operation or case mechanics. I have provided examples; adjust as needed.

### Key Concepts, Content Knowledge, Skills

### Accessing Cases & Facilitator Notes

### How Students & Facilitators Submit Evaluations

### Institutional Supports & Resources


## Facilitating Group Learning

> Focus here on what instructors should DO within the cases and course framework.


### What is the Role of a Facilitator?

> This section describes the ideal roles facilitators will play in the local program. Explain what facilitators SHOULD do, but at the same time stress that no facilitator will be perfect. In practice every facilitator shows strengths and weaknesses when they lead student groups. Like students, they grow and develop with time and experience.


### Orienting Students to the Course

> How should the instructor introduce students to the case model?


### Typical Workflow

> The subsections below assume a 2-session interrupted case. Adjust them to fit your case model.


#### Before 1st Session

#### During 1st Session

#### Between Sessions

#### During 2nd Session

#### Debrief

#### After 2nd Session


### What Effective Facilitators Do

> If you have any prior experiences to draw on, what is or is not effective with students locally?

#### Asking Effective Questions

#### Sample Prompting Questions


## Troubleshooting Group Process

> Subsections in this part of the guide should focus on problems that you see most often locally. I provided examples of some common challenges._

### Quiet Students

### Dominating Students

### Students Get Off Topic

### Students’ Knowledge, Logic Is Inaccurate

### Students Resist Doing Group Work

### Groups Do Not Work Well Together


## Evaluating Students and Cases

### What Will Be Evaluated?

### Formative Assessment

### The Summative Assessment (Grading) Process

### Grading Criteria and Format


## Sample Course Documents

> Include copies (with instructions) of the current evaluation documents for the course.

### Form: Student Self-Evaluation

### Form: Facilitator Evaluation of Student

### Form: Student Evaluation of Facilitator

## Literature Resources

## Case Outlines

> Provide short (<1 page) outlines summarizing:_

* Learning goals
* End products
* Typical class flow, time required
* Individual instructors’ observations, notes on:
    + Common trouble spots
    + Possible adjustments, modifications


 
Introduction

Welcome to the Scientific Professionalism Courses. This guide provides supporting information for facilitators working with students in the following courses.

	GRAD713 & –714:  Scientific Professionalism and Integrity 
	GRAD715 & –716:  Scientific Professionalism: Bioethics and Social Responsibility  

Science and technology are daily changing the social environment we inhabit. Consequently, new ethical situations face us that did not exist a few short years ago. Part of our responsibility as teachers of graduate-level students is to provide them tools with which to navigate the complex and rapidly evolving academic and societal environments of their future. While this course will fulfill the ethics requirement of the graduate school, these courses aim to do more. Their goal is to help transform graduate students into scientists and engineers with a high commitment to professionalism and social responsibility, who are fully cognizant of their role obligations as scientists and engineers.  

This guide is meant to be useful for both the experienced and inexperienced facilitator alike. For novices who are unfamiliar with the curriculum and its goals, Part 1 provides a short overview of the entire course in just a few pages. Parts 2–7 discuss each component of the course in detail. They describe the ethical principles on which the course is based, the mechanics of facilitating the course, how to guide students through the group learning process and assess them, managing group dynamics, and how to troubleshoot common course problems. At the end are samples of assessments, syllabi, and other course documents, and a list of references relating to the course.

As the facilitator, you are key to the success of these courses. You also have the best insight into how to improve the content and course process. Please do not hesitate to provide the Advisory Committee with feedback about how we might improve specific learning objectives, or the course overall.

 
Course Catalog Descriptions


GRAD713, GRAD714: Scientific Professionalism and Integrity
(2 semesters, 1 credit each semester) 

The students will use the Problem-Based Learning (PBL) method to identify discipline-specific and broad professional norms and obligations for the ethical practice of science.  Content will include the norms and principles for the responsible conduct of scientific research such as data acquisition, management, sharing and ownership, publication practices, and responsible authorship. Emphasis will be placed on learning the tenets of responsible conduct of research, the current regulatory and legal climate, as well as the underlying norms and principles that shaped these concepts.  Topics will include the student and advisor relationship, laboratory dynamics, collaboration in science, appropriate handling of data and appropriation of credit, plagiarism, conflicts of interest and financial responsibility. Students will acquire skills to recognize ethical issues in the practice of science, identify role obligations, and develop sound ethical reasoning to address these issues. 




GRAD715, GRAD716: Scientific Professionalism — Bioethics and Social Responsibility
(2 semesters, 1 credit each semester, prerequisite of 1st year course)

New discoveries in science and technology are changing the social environment we inhabit with increasing frequency. Consequently, the next generation of scientists faces new ethical situations that did not exist a few years ago.  Science’s special place in society allows considerable freedom for discovery that is based on the integrity and social responsibility of scientists. Students will use the Problem-Based Learning (PBL) method to explore the ethical issues within the scientific profession and the implications of science developments for society.  Emphasis will be placed on learning not only the current policy, regulations and legal issues, but also the underlying ethical principles, norms, and values at play.  Topics will include entrance of bias into research, limits of scientific authority, conflicts of interest, peer review, human and animal subjects, commercialization and globalization of science, scientific freedom and responsibility, and right of conscience.  Students will acquire skills to recognize ethical implications of science for society, to identify role obligations of individual scientists and scientific organizations, and to use sound ethical reasoning to address these issues. 

 
Part 1: A Brief Overview of the Curriculum

What is the Purpose of This Course?
The scientific community is a culture whose members share similar values, live and work together, and have obligations and responsibilities to each other. They also have certain expectations of each other. The scientific community has established a consensus set of norms that define how we expect each other to behave. In return for living by those norms, members of the scientific community gain certain rights and privileges. What exactly are those values? What are the norms? What are reasonable and unreasonable expectations? What is the penalty for violating the rules of the scientific community?

Most established scientists have had enough experience that they can provide fairly well–reasoned responses to the aforementioned questions. However, every new group of scientists in training must learn the norm and expectations for themselves. Sadly, more and more instances are coming to light of scientists who never learned how to act as a responsible member of the scientific community, or who intentionally disregarded scientific norms.

What we do as scientists potentially can have tremendous impact on other human beings (many of whom are not members of our community) and on the world in which we all live. This reality points to larger questions. What are scientists’ obligations to the rest of the world? How can we best decide what those obligations are? How do we know if we are (or are not) meeting them?

The goal of this four–course sequence is to provide new members of the scientific community (i.e., graduate students, post–doctoral fellows, and other trainees) with thinking skills so they can ask and answer these kinds of questions. More specifically, this course sequence has 7 formal goals (in educational parlance, learning objectives):

•	Acquire skills to recognize ethical issues in the practice of science
•	Identify professional role obligations of scientists; such as graduate students, postdoctoral fellows, principal investigators and technicians
•	Identify norms for the responsible conduct of scientific research, such as data acquisition, management, sharing and ownership, publication practices, and responsible authorship
•	Develop sound moral reasoning to address ethical issues in the practice of science, such as identifying the points of ethical conflict, the principles, obligations, and consequences of a chosen course of action.
•	Develop skills for effective group work, such as clear communication, facilitating other group members to contribute, focusing on key concepts, moving discussion forward, and constructively critiquing others’ concepts 
•	Develop self-directed learning skills, such as increasing their ability to identify key learning issues in a situation, seek out and acquire new content knowledge, identify appropriate resources and apply their knowledge in ways that help them resolve those learning issues. 
•	Gain specific factual content knowledge that relates to these issues and skills. 
 
Is This an RCR Training Course? A Bioethics Course? Something Else?
This course combines many elements. If you have not heard of it before, RCR is short for “Responsible Conduct of Research.” DHHS includes 9 topics under the RCR umbrella, and a good portion of RCR training focuses on learning how to conduct research in a responsible way. RCR training seeks to teach members of the scientific community how they should behave (for example, who should have authorship on papers, and how mentors should treat trainees.) and what rules and regulations are in place that affect how we conduct research (rules for protecting human subjects, for example.)
 
There has been a growing movement to require formal RCR training for all graduate students and post–doctoral fellows. Unfortunately, current evidence suggests that simple lecture–based training is not effective at preventing inappropriate behaviors while conducting research. To effect a positive change in behavior, trainees need to understand the rationale behind the rules and regulations. This is where bioethics comes in. Many bioethics courses focus on formal theories and ethical decision–making models. These theories can provide trainees with a framework for thinking about the rationale behind the rules. Yet formal ethics training can also fall short. If students have no opportunity to practice applying ethical principles, then they are unlikely to use them when faced with an ethical or professional dilemma.   

The four–course sequence described here uses case–based teaching to place students in the center of a professional dilemma. Some cases address each of the nine topics recommended by the current RCR training standard. Other cases focus on roles and obligations of scientists to each other and to society at large. Through the courses, trainees learn basic ethical decision–making skills, and are expected to develop more complex moral reasoning and reflection skills. They also learn how to untangle complex questions and respond in a well–reasoned manner. 


What Exactly is Problem–Based Learning?
Many ethics courses use case studies. What makes our program unique is that students approach cases through a specific group instructional process called problem based learning (PBL). The PBL teaching method has been used by WFUSM since the 1980s to teach clinical science to medical students. It is also used in a variety of other settings at other institutions. Two fundamental ideas drive PBL: 1) a student learns best when they are active participants in the learning process, and take the lead in identifying and locating relevant information; and 2) students learn more effectively in groups than alone.

Details of the PBL process are explained in a later section. For now, it is enough to know that students in these courses work through case scenarios in stages. At each stage, students must determine what they know as facts, what they would like to know, and what pieces of information (called learning issues) they would need to learn to continue. As each case unfolds, a serious conflict related to RCR or some other role obligation of a scientist emerges. Students work as a group to identify the issues raised by the case and resolve them. In PBL, learning is largely self–directed. The facilitator is NOT the source of final authority. Rather, the facilitator guides the group during the learning process. Later sections describe in detail how a facilitator fulfills their role as “guide on the side” for the group. 

PBL is a thoroughly validated instructional method. Time and again it has been shown to produce greater learning gains than didactic lectures. Yet those who have never experienced it often do not believe it will work. It is true that, when implemented improperly, it can be a disappointing experience. This guide explains how to use PBL correctly, and troubleshoot the most common problems. It is also true that facilitating a PBL course is more challenging for instructors than traditional didactic lectures. In a lecture, the instructor feels they have good control of the pace, direction, and types of learning that occur. Ironically, educational research indicates that, while the lecturing may feel more comfortable for the instructor, the amount their students learn is less, the information learned is retained for less time, and students are less able to use it. A PBL facilitator must be able to adapt, and let the learning process happen at its own pace. The reward is deeper and more useful learning.

One common concern of PBL novices is how to assess students. Fortunately, this format has been used for so long at WFUSM that many scoring rubrics and assessments have been developed and are available already. The last section of this guide provides an extensive explanation of how to evaluate students, including instructions for the rubric to be used. There also are sample scoring sheets in the back to use as a general guide.

This guide provides the general instructions you will need to begin facilitating classes in this course sequence. There will be additional information that relates to each specific case. This is summarized in the Facilitator Case Notes, which are posted online in the same location as the cases themselves. With time, the ideas and techniques contained in this document will tend to become second nature. The course developers do suggest that you look back at this document from time to time. The notes for each specific case should be reviewed every time you go in to lead a group through the discussion of that case.

 
Part 2: Ethical Principles and Models

This section describes the ethical principles and theories on which this course is based. It also explores some of the controversies around the various model systems. This is not a body information that you will share directly with students, or that we expect them to locate on their own. Rather, contains background on the two specific ethical decision–making models that students will be using during this course. It also it provides you as the facilitator with supplemental background knowledge that you can use to enrich the case discussion. 


Is This An Ethics Course?

This course does fulfill two requirements for ethics education and training of trainees, e.g. 1) the responsible conduct of research (RCR) and 2) human subject protection (HSP) requirements (Note the HSP requirement is only for trainees engaged in human subject research).   But this is not an ethics course per se, nor is it just a course that focuses only on compliance with rules and regulations.  

The goal of this course is to assist in the transformation of graduate students into scientists and engineers with a high commitment to professionalism and social responsibility fully cognizant of their role obligations as scientists and engineers. 

NIH trainee RCR educational requirement: Trainees of all research including animal, human, and basic research, or research training, conducted with grant, contract, or cooperative agreement support from any agency, or office, of the PHS (includes NIH) are required to have a basic program of instruction in the responsible conduct of research (PHS Policy on Instruction in the Responsible Conduct of Research (RCR) http://ori.dhhs.gov/policies/RCR_Policy.shtml established December 1, 2000 and required by October 2003).

NSF trainee RCR educational requirement: The America COMPETES Act (Public Law 110-69 Section 7009 http://www.whitehouse.gov/news/releases/2007/08/20070809-6.html) passed by Congress in 2007 calls for the NSF director to ensure that NSF proposals describe a plan for training and oversight in the responsible and ethical conduct of research to undergraduate, graduate and postdocs participating in the proposed project. The exact policy at NSF is under construction. 

NIH Human Subject Protection (HSP) educational requirement: NIH requires education on the protection of human research participants  for all key personnel (those involved in the design or conduct) on NIH applications for grants or proposals for contracts or receiving new or non-competing awards for research involving human subjects. http://grants.nih.gov/grants/guide/notice-files/NOT-OD-00-039.html  Human subject as defined in 45 CFR part 46 means a living individual about whom an investigator (whether professional or student) conducting research obtains: (1) data through intervention or interaction with the individual, or (2) identifiable private information.  Note the Office of Human Research Protection (OHRP) is exploring proposing a rule to require those involved conducting human subject research or with oversight such as serving on a Institutional Review Board (IRB) be required to have education on HSP (July 2008).

Why Are We Not Teaching Ethical Theory? 
The main focus of these courses is to enable our student to acquire the values and norms of science and become professionals by assimilating with the culture of science. The courses also introduce four types of moral reflection to ensure the students have a robust exposure to the ethical issues and norms in the practice of science.  We also introduce the students to two methods for moral reasoning that appeal to ethical theories. But the courses do not teach ethical theories per se, nor do the courses take a compliance-based approach that focuses mainly teaching rules and regulations of science.  

The reasoning is best understood by answering another question, “does learning ethical theory and philosophy or learning rules and regulations ensure that someone will behave ethically?” In fact research has shown that training in rules, laws, or RCR does not change behavior or ensure that someone behaves ethically. It can actually have the opposite effect (Anderson et. al. 2007).  


What Does Influence Ethical Behavior Positively? 
One factor that influences ethical behavior is someone’s identity and belonging to a social network or culture that has a strongly embedded ethos.  Research has shown that strongly implemented and embedded ethical codes of conduct within organizations influence ethical behavior.  An essential element for helping individuals internalize norms and values is open communication and socialization to cultural norms (Anderson and Louis 1994; Anderson 1996). 

The small group design provides this high degree of socialization around professional behavior with peers and role models—the facilitators.  Even better is to have these discussions within all types of activities and interactions with students, such as lab meetings, informal conversation, other classes, journal clubs and seminars and national meetings. 


Facilitators are Key to Ethics Training!
Highly respected scientists with high status, resources, symbolic value, affect the degree to which members of organization internalize the norms associated with responsible conduct of research as does the ethical tone of leaders at every level (Pfeffer, 1981, Siehl and Martin 1984, OGE 2000).
This is why the facilitator’s presence, participation, and attitude are the key to the success of this course. You are a role model up close and personal. The values and professionalism you exhibit speak louder than any other learning activity. Take your obligation seriously as you train the next generation to join the community of science.

 
Is It Even Possible To Teach Ethics? Isn’t This Something You Should Have Learned In Kindergarten? 
There is no doubt that the moral underpinnings learned early in life are highly influential in someone’s future ethical conduct. However, it is equally important to recognize that graduate students come from every conceivable cultural and moral background possible. Therefore it is imperative not to assume that everyone is operating from the same underlying cultural norms, but rather explicitly train students in the expectations and norms for practicing science.  

More to the point, our science graduate students should now be considered as members of the culture of science on their way to becoming scientific professionals!  Moreover, “…the correct conduct of science cannot have been learned in childhood since many scientific practices (e.g., authorship practices, the confidentiality of peer review) are not elements of childhood.”  (Jones 2007) Our role as facilitators and members of the scientific community is to transmit the cultural norms of science to the next generation.  

Ethics is Personal
Feedback from previous years indicates that some students think ethics is personal and they are uncomfortable and/or think they shouldn’t be required to discuss openly what they consider to be personal decisions.  However, the students have now joined the community of science and need to be able to justify their decision(s) and choice of action(s) as a professional. As students practice moral reasoning it is also important to communicate that not all justifications are equal and in fact some are not credible. Justification should be based on sound moral reasoning, by appealing to principles, obligations, and consequences. For example, a justification might ignore the professional norms of the science community. As facilitators, encourage discussions on the rigor of the arguments presented and discuss how arguments can be strengthened.  As always, encourage critique of merits of the argument itself, not the person presenting the argument. 

If students are uncomfortable discussing ethics, one teaching method is to ask the students why it might be important that professionals be able to justify their actions to peers (and society). Use that discussion to remind your group that they have now joined the community of science, and that professionals need to be able to justify their actions to peers (and to society). 

One other important point is that the community of science allows the right of conscience (i.e., one can object to something on personal moral grounds).  For example, someone can be a scientist but for personal moral grounds choose not to work on animals or fetal tissue. If someone has such strong convictions about a particular area of research that they believe should be changed, there is a tacit agreement that those differences should first be worked out within the community of science through existing channels, such as professional societies and research oversight committees of the university system.  Generally, there is a disdain for “whistle-blowers” who expose practices to the general public without trying first to remedy the problems within the scientific community.  

 
What are the Ethics for Science?



Code of Ethics for the Life Sciences


Goal of Science

The biological and biomedical sciences have the ultimate goal of advancing human health and welfare of all human beings.  Scientists and the scientific community accept the responsibility to act on behalf of the interests of all people, and will guide society in the development of safeguards necessary to judiciously anticipate and minimize harms.

Principles for the Practice

Objectivity	Honest assessment and minimization of the biases inherent in science, i.e. cultural and other influences on the experimental design, techniques and interpretation of the data.
Questioning Certitude	Questioning current authoritative view or dogma in order to continue the process of advancing new knowledge.
Research Freedom	Allowing ideas to flourish within the scientific community because wrong or true concepts will eventually be proven as such.
Research Reproducibility	Quality scientific research can be re-proven and is openly available to all qualified scientists to move knowledge forward.
Respect For Subjects	The highest ethical standards are upheld to respect all living things, with profound respect granted to human life and dignity.
Scientific Community	The scientific community is the guardian for the integrity of science by proving the veracity of individual findings through peer review and reproducing experimental results, and by training and accrediting future scientists.

Virtues

Duty	Scientists are committed to serve and guard humanity and seek to advance scientific understanding and respect for the truth.  
Integrity	Scientists strive to be objective, fair, truthful, and accurate.

Accountability	Scientists are accountable to their profession and society. 
Altruism	Scientists’ primary focus is the best interests of humanity and not self-interest, commercial interests, or the promotion of the industry of science.
Excellence	Scientists are committed to a lifestyle of learning and transmitting knowledge and skills.
Respect for colleagues	Scientists treat associates and trainees with respect and credit their contributions.
 
Is Ethics Subjective Because Different Methods Come Up With Multiple Answers?
Scientists often dismiss philosophy and ethics because they think it is subjective and non-rigorous.  It can be true that the practice of philosophy is difficult to appreciate for those outside philosophy. However, many similarities can be drawn between the practice of science and the practice of philosophy. Philosophy’s aim is to provide theories that can explain the truth. But just like a single science paper should not be construed as definitive truth, neither should one philosopher’s work be construed to represent the truth. Just like science, ethical theories and systems have presuppositions, strengths and weaknesses in their various methods and the theories are under continual testing and refinement.  Additionally, philosophy and ethics have their findings scrutinized through peer review and further testing by new thought experiments by other philosophers.  Another similarity to science is that the philosophy community can reach consensus about the limitations, strengthens and accuracy of various theories and arrive at conventional wisdom.  

Another difficulty for scientists is that often there is no single correct answer; rather there often are many morally permissible answers.  While a single method or multiple methods can show that many answers or actions are morally permissible, it is important to recognize that certain actions are clearly wrong e.g. not morally permissible. When there are multiple morally permissible answers, some answers are more prudent than others, but that does not change the nature that the other actions/answers are still morally permissible.  

 

There are also other answers that are exemplar—an ideal action that goes beyond normal moral expectations.  An example of an exemplar is a solder that throws his body on an exploding grenade to save the life of his fellow solders. Another example of an exemplar would be a principal investigator who encourages their former postdoctoral student to take over a hot area uncovered during their postdoctoral work in their new faculty position at a different university without assigning any personnel from his/her laboratory to work on the area. 
 
Strategy for Ethics Training

Our goal is for students to:
1)	Be acculturated in the norms, principles, values of science and virtues and obligations of scientists and 
•	Gain skills to recognize ethical issues in practice of science and the ethical implications of science for society and learn sound ethical reasoning to address these issues. 

GRAD 713&714 focuses on norms and ethical issues related to the practice of science. Students will identify discipline-specific and broad professional norms and obligations for the ethical practice of science.  For example student will learn about role obligations of graduate students, mentors, and technicians as well as the norms and principles for the responsible conduct of science such as data acquisition, management, sharing, and ownership, publication practices and responsible authorship. 

GRAD 715&716 extend the discussion to the ethical issues within the scientific profession and implication of science for society.  Emphasis will be placed on not only learning the current policy, regulations and legal issues but also the underlying ethical principles, norms, and values at play.  Topics will include entrance of bias into research, limits of scientific authority, peer review, commercialization and globalization of science, and scientific freedom and responsibility.

The questioning of the cases is designed to promote moral reflection and discussion of professional norms and obligations.  

Moral Reflection 
Four types of moral reflection will be stimulated (though not necessarily all in any one case): moral sensitivity, moral reasoning and judgment, moral motivation and commitment, and moral character and competence (Bebeau, Rest, & Narvaez 1999, Rest, Narvaez, Bebeau, & Thoma 1999).  

Moral sensitivity is the ability to see things from the perspective of others and to be aware of legal, institutional, and national concerns. The goal is to promote sensitivity to ethical issues that are likely to arise in research settings.  
Teaching strategies include presenting situations where the ethical issues have not been predigested or interpreted.  The students will need to be aware of nuances in the case scenarios and sort through relevant and irrelevant information in order to focus on pertinent research customs, rules, regulations, and laws.  One tact used to highlight moral sensitivity is asking the students to consider something from another’s point of view. 
 
Moral reasoning and judgment involves learning ways to weigh the principles, values, and consequences embedded in moral judgments.  The goal is to teach some concrete methods or frameworks for scientists to work through ethics.
The teaching strategy is to force a choice or decision to assure eliciting reasoning rather than problem solving with several possible solutions.  Students will be prompted to defend their choices by supplying the criteria for their judgments. The course will use two approaches or methods for developing moral reasoning, 1) “Developing a Well-Reasoned Response to a Moral Problem in Scientific Research Ethics”(Bebeau, Pimple et al. 1995). And 2) Three quick ethical questions adapted from: Iserson, Ethical Issues in Clinical Emergency Medicine (1999) 17:283.  See below for further explanation of the methods with examples.  

Moral motivation and commitment aims to develop a sense of professional identity. The goal is to instill a sense of personal identity that incorporates the norms and values of the science culture.
Teaching strategy is to cause the students to consider their choices and decisions based not just on role obligations as a friend, student, and parent but asking students to explain what their obligations are as science professionals. Characters are included in the cases that provide exemplary examples for working through the issues instead of only portraying the worst scenario examples.
Moral character and competence reflects a focus on personal skills such as interpersonal interaction and problem solving. The goal is to build competence in problem-solving and interpersonal skills.
Teaching strategies include role playing exercises.  The small group format and emphasis on learning how to work within groups focuses on this aspect of moral reflection. 

Ethical Theories: 
•	Define what is right and wrong
•	Prescribe how you ought to live
•	Ideally have a method/system to make ethical decisions 

Not all decisions are moral or ethical. Some decisions are preferences or prudence.  Words that imply a moral judgment are 1) good or bad, 2) right or wrong, 3) ought or ought not, and 4) should or should not.

There are two major types of ethical theories. Moral obligation theories are systems that tell you what the right thing to do is and focus on the morality of the action. Virtue theories are systems that show what kind of person you ought to be and focus on the morality of actor. Moral obligation theories prescribe thoughts and actions but are inadequate to change motivations. Virtue theories on the other hand prescribe altering the actor or motivation by acquiring virtues, but do little for prescribing the right and wrong actions. 
 
A. Moral Obligation Theories 

•	Tells you the right thing to do (action)
•	Morality of the action itself

There are two types of moral obligation theories, 1) deontological theories and 2) consequentialism (utilitarian) theories which both focus on the morality of the action but use different methods.  

 

1.	Deontological theories the action is intrinsically considered right or wrong  
a.	Act itself is Right or Wrong
b.	Appeals to principles, imperatives and duties
c.	Intrinsically binding on people
•	A major theorist was Immanuel Kant
d.	Examples of principles are: justice, truth, freedom, respect for life
e.	Two major deontological theories are 1) natural law ethics which derives the principles from man’s reason of nature and 2) divine command ethics which ascribes the source of principles to God. 
f.	Critiques of deontological theories include 1) it begins with the limitation of appealing to a moral tradition to establish the principles, 2) principles are subjective and not universal, and 3) most methods lack a way to order or prioritize between principles.
g.	Common deontological phrase is “The ends (consequences) DO NOT justify the means (actions)”
h.	Note that deontological theorists have a concern for consequences, but consequences are not used to define morality of action. However the likelihood of better consequences can be used to prioritize between options that are morally permissible or morally neutral. However, a good consequence cannot be used to define a morally non-permissible action as good. 

2.	Consequentialism theories in contrast define the action as right or wrong based on the outcomes.
a.	Consequences determine if an action is moral rather than act itself
b.	The principle of utility decides the ought, rightness or wrongness of the act by determining the amount of non-moral use it produces, such as happiness and pleasure
c.	Teleological ethics asks about whether it is a good or desirable end to achieve
d.	Two major theorists were Jeremy Bentham (1748-1832) & John Stuart Mill (1806-1873)
e.	Two major categories of Utilitarian theories are Act  and Rule 
i.	Act- the consequences (ends) of each action needs to be examined to decide if an action is right or wrong
     Critique is that often troublesome and counter intuitive for things like slavery or risky medical research which can be justified (Caiaphas principle: “isn’t the society that sacrifices one life for the lives of many better?”)
ii.	Rule- the rightness of the action is based on the greatest utility to a culture or society. This informs how an individual should act within a culture.
     Critique is 1) that there is a hierarchy of pleasures but who/how are pleasures to be prioritized or ranked and 2) it is difficult to accurately assess consequences for action prior to the action occurring. 

B. Virtue Theories
•	Tells you what kind of person you ought to be 
•	Morality through the agent and motivations 
•	If the agent has a moral character e.g. virtues, then his or her actions will be moral 

1.   The first Virtue Theory
a.	Aristotle (384-322 BC)
b.	Chief end or highest good
c.	Ethics is the discipline that seeks to find what happiness really is
d.	Moral virtue is obtained through achieving the golden mean 
e.	A moral mean is a balance between vice of excess or vice of deficiency
f.	Critique is that it does not prescribe rights and wrongs and a means of decision-making
 
 2.   The Cultural Backdrop to Current Ethical Theories
	The current generation has several other ways of thinking about ethics, including:
•	Ethical Subjectivism
•	Cultural Relativism
•	Pragmatism: resonates with scientists in particular.

a.  Ethical Subjectivism
i.	Nothing is moral or non-moral
ii.	Ethical statements are merely an expression of the subject or individual such as feelings or opinions
iii.	No universal principles/law or Truth
iv.	Does not prescribe how to live 
v.	Does not define what is right or wrong
vi.	Critique of this system 
•	Does not allow for solving ethic disagreements because there are no real moral disagreements, rather differences of opinions and 
•	Ethical subjectivism often holds up tolerance as a universal principle, which is internally inconsistent with the premise of ethical subjectivism that there are no universal principles. 
•	Ethical Subjectivism does not work in science. Science holds that data should be accurate and true.  For example, if the data point was “1.0”on the first day it will always be “1.0.” However, science may gain a new understanding of the limitations of the experimental design or instruments the data were collected on or other studies may influence the interpretation of what “1.0” means, but the data will never change.

b.  Cultural Relativism
i.	Moral beliefs and practices are merely socially approved habits derived from culture
ii.	Denies universal law or principles
iii.	Not a normative ethical theory
iv.	Cannot prescribe oughts
v.	Critique of this system
•	Falls short as a normative ethical theory because it cannot prescribe behavior but rather describes underlying motivations of behavior
•	Lacks ability to decide between cultures or mediate conflicts.
•	Society has a social contract with science and expects that science will adhere to cultural norms.

 
c.  Pragmatism
i.	A philosophy that is often appealing to scientists
ii.	Pragmatism considers real or practical consequences in addition to theory when deciding what should be done
iii.	Theory is an abstraction of practice, therefore theory must come back to practice to hold true
iv.	Popularization of pragmatism is that the morality of actions can be dismissed if they cannot work— so what works or is practical, becomes what is right.  For example, if the concept is an unobtainable ideal but can’t work it can’t be right.  
v.	Critique of this system 
•	Society has a social contract with science and expects that science will adhere to cultural norms.
•	The scientific community often esteems nonconformists and mavericks that break paradigms to make startling discoveries. While sometimes social conventions need to change, it is not for scientists to ignore public sensibilities (particularly if they are supported by public monies). This seems like pragmatism, but in fact, scientists are appealing to the principle that acquisition of knowledge is primary and always good. “But rather than disregarding public sensibilities, appealing that the ends justify the means, or breaking conventions to prove one’s case; scientists need to work with society to shape the concepts of ethical practice.” (Jones, NL (2007) Science Engineering Ethics 13:25)

d. Norms for Science
i.	Science is a culture and appeals to its own ethical system
ii.	Science has Principles for Practice (Moral Obligation-Deontological)
iii.	Scientists have role obligations
iv.	Expectations for the virtue or character of scientists (Virtue Theories)
v.	There is an implicit social contract that both the research and researcher will act with integrity in the best interests of society.


 
A Code of Ethics for Life Sciences 
 “The Prototype Code of Ethics for the Life Sciences is concerned with consequences, defining the overarching purpose of the life sciences as acquiring knowledge for the betterment of mankind. The code also prescribes principles for the practice of ethical science and virtues for scientists.  The correct outcome or consequence is important, but the practice is important as well, because if the experiment is not reproducible, then the results are not reliable and the conclusion is worthless for the furthering of science.  Equally important are scientists with the virtue of integrity.  Different types of ethical theories have strengths and limitations for defining ethical behavior.  Focusing on outcomes can promote distributive justice assuring the applicability of science for all mankind, but concern only with an outcome can condone unethical means of acquiring knowledge.  Principles for the practice of science assure the reproducibility of science, and gain relevance when science links its activities to the outcome of bettering mankind.  Developing scientific virtues is helpful for motivating ethical behavior, but provides little help in decision-making and prescribing the right and wrong actions when principles conflict.  Combining these theories allows for a more comprehensive ethical framework for science.” 

(Jones, NL (2007) Science Engineering Ethics 13:25)


 
Moral Reasoning Methods

There are two moral reasoning methods that scientists can use to examine ethical problems. They combine a number of ethical theories to more systematically check the rigor of justifications. These are the two strategies that we are teaching students to use in the GRAD713–716 course sequence.


Developing a well-reasoned response to moral problems in science 
Bebeau’s method that can be found at http://poynter.indiana.edu/mr/mr-developing.pdf. Indiana University has made its extensive resources for teaching and learning bioethics and moral reasoning publicly available at http://poynter.indiana.edu/mr/mr-main.shtml. There is a full booklet in PDF format with examples of applying the method.   

In this method of moral reasoning, students are asked to identify the: 

1.   Issues or underlying moral conflicts
	What is in conflict is more that the “issue”, rather usually principles are in conflict.  

2.  Stakeholders in the issue
A stakeholder is someone with a vested interest in the situation. Often this goes beyond the immediate characters in the conflict. 

3.  Obligations the stakeholders may have
	Obligations can come from professional roles, religious sources, family, culture, etc. 
 
4.  Actions one could take, and the likely consequences of those actions
This can help decide between several morally permissible actions by examining what are the likely effects of an action 


Three quick ethical questions
The questioning was adapted from a form of moral reasoning by Iserson, Ethical Issues in Clinical Emergency Medicine (1999) 17:283.

1.	Would you be willing to have this action performed if you were in the other person’s place? 
a.	Is the decision biased toward self? 
b.	This examines the “Golden Rule”, i.e., do unto others as you would have them do unto you. In other words, this is intended to correct partiality or self-interest bias.

 
2.	Universalizability Test:  Would you be comfortable if all “scientists” with the same background and in the same circumstances act as you are proposing to do? 
a.	Can this work if this is the rule rather than exception?
b.	This is based on Kant’s Categorical Imperative, what would the world look like if everyone acted this way?  This is intended to prevent short-sightedness, if a rule would be difficult to maintain question why.

3.	Justifiability Test: Am I ready to state openly to my peers, superiors, or the public my reasons that I acted as I propose to do? 
a.	Does my reasoning/justification hold up for others?
b.	Willing to be transparent allows others to critique the underlying reasons and justification for the actions.  If the reasons are weak or go against norms, this will be exposed. 



Sample Cases Comparing The Two Methods 

Sample Case 1



Method 1: Developing A Well-Reasoned Response To A Moral Problem in Science

•	What are the issues or points of conflict? 
–	Ben’s family responsibilities versus graduate student responsibilities
–	Ben’s desire to remain in graduate school versus doing ‘ethical science’ 

•	Who has a stake in this? 
–	Ben (and family) 
–	Lab rotation advisor 
–	Graduate program
 
•	Who has obligations, duties or responsibilities and what are they?
–	Ben has obligations to take care of his family
–	Ben has obligations for ‘ethical’ science
–	Advisor/Program Director has obligations to help Ben make wise choices and be an advocate

•	What are possible actions and their consequences?
–	Ben can make up data so he can have more time to focus on studies, but it may be detected and could also remove him from the program
–	Ben can get in the lab and do the experiment, perhaps will not get an A and be out of the program
–	Ben can ask for help from the advisor or program director, perhaps get an extension. Maybe he will gain a reputation of not working hard enough or not handling the stress adequately, or that he is dealing with stress in a responsible manner. 


Method 2: Quick Ethical Decision Making

•	Impartiality Test
–	If Ben was the advisor, the student’s action could jeopardize laboratory’s standing and career if data was released somehow, or it influenced co-workers experiments.

•	Universalizability Test
–	If all students (or faculty) fudged data when “stressed” no research data could be trusted. (When are trainees not “stressed”?)

•	Justifiability Test
–	Ben would be hard pressed to be transparent with everyone about what he had done. His rationale would not be justifiable to the laboratory advisor, graduate dean or public.  Easier to ask permission not to do the experiment.
 
Sample Case 2


Method 1: Developing A Well-Reasoned Response To A Moral Problem in Science

•	What are the issues or points of conflict? 
–	Appropriate attribution of credit for scientific work
–	Competition between students (comparisons, rumor -mills, back-biting)
–	Romantic relationships in the work place
–	Acknowledgement/Authorship of Work
–	Fairness in academic program and awards
–	Running a successful graduate program versus overly catering to student and faculty wants

•	Who has a stake in this? 
–	Sara
–	Ethan
–	Fellow lab members/graduate students
–	Research advisors of Sara and Ethan
–	Department Chair and/or program director

 
•	Who has obligations, duties or responsibilities and what are they?
–	Sara has an obligation to give appropriate credit for contributions to her publications. 
–	Ethan as a fellow graduate student can help with Sara’s work, but he has obligation to his advisor and ‘slot’ as graduate student. Someone is paying his support, which is not to be “Sara’s technician”. 
–	Ethan’s advisor should be responsible for Bill’s progress. 
–	Program director has responsibility for integrity of graduate program and creating productive environment for both faculty and students to excel and conduct research with integrity.

•	What are possible actions and their consequences?
–	Hold Ethan accountable to not performing his work in a timely manner.  
–	Hold the advisors accountable for progress of students. 
–	Sara is basically gone, bring negative publicity at best or create a scandal by taking back her award?  Recommend her to a company because of her ingenuity?
–	Do nothing, it will blow over or create low moral for other graduate students


Method 2: Quick Ethical Decision Making

•	Impartiality Test
–	If the Sara was a student who worked hard but did not have technical help she might resent someone who got extra help.  If Ethan was in the graduate program directors place he could think it a waste of resources to have a student take a graduate student slot and not have a productive project. If Sara was in the biotech employer’s place she might resent hiring someone who misrepresented their work capabilities (or admire someone who can get others to work for them).

•	Universalizability Test
–	If all graduate students worked on other people’s projects rather than their own, graduate programs could not sustain funding of their programs.

•	Justifiability Test
–	If Ethan’s contribution to Sara’s work is known, it could jeopardize the reputation of the award and graduate program reputation that allows one student to claim another’s work as their own.

 
Part 3: Responsible Conduct of Research

What Exactly is Responsible Conduct of Research?
Science is built on a foundation of honesty, collaboration, and open access to information and resources. Members of our community are expected to meet high standards of integrity, accuracy, and objectivity. Sadly, these ideals are eroding. Research misbehavior and misconduct are being reported ever more frequently. Each time a case of misbehavior or misconduct comes to light, public confidence in science and support for it declines further. In response, many federal agencies now require all undergraduates, graduate students, and post–doctoral fellows supported by their grant dollars receive formal training in Responsible Conduct of Research (RCR). Put simply, RCR is nine content areas that students should be trained on the guidelines and standards for conducting and reporting research in a discipline.


Who is ORI, and what is their relationship to RCR?
The Office of Research Integrity (ORI) is an agency within the US Department of Health and Human Services. Officially ORI’s mission is to oversee and ensure the integrity and accuracy of research conducted by Public Health Service (PHS) agencies. PHS agencies that most concern biologists are the:
•	National Institutes of Health (NIH) 
•	Centers for Disease Control and Prevention (CDC)
•	Food and Drug Administration (FDA)
•	Substance Abuse and Mental Health Services Administration

Responsibilities of the ORI include:
•	Developing policies, procedures and regulations related to the detection, investigation, and prevention of research misconduct.
•	Reviewing, monitoring, and assisting with investigation and prosecution of research misconduct investigations.
•	Providing technical assistance to institutions as they respond to charges of misconduct.
•	Implementing activities and programs to teach the responsible conduct of research, promote research integrity, and prevent research misconduct.

	Unofficially ORI has become the main resource and opinion leader on issues relating to RCR, both in and outside of the federal government. Many ORI statements of policy and training guidelines have been adopted by other federal agencies, including the National Science Foundation. Together NIH and NSF control the overwhelming majority of science research dollars in the United States. Given their commitment to RCR, it is probably safe to assume RCR training will be a requirement for all scientists in the very near future. The WFU Graduate School is anticipating this requirement by developing and implementing a broad cross–campus RCR training program. 


What Is The Purpose And Purview Of RCR Training?
Scientists believe that enforcement and stricter government oversight are NOT the best ways to encourage RCR. Instead, their consensus is that well–designed training programs will be the most effective way to reduce the incidence of misbehavior and misconduct. The basic goals of RCR training are to:
•	Raise situational awareness, so individuals are not caught in or negatively affected by misbehavior or misconduct of other scientists (mentors, peers, etc.) 
•	Reduce the likelihood that individuals will engage in misbehavior or misconduct themselves. 

There is no one uniformly accepted set of topics, curriculum, length of training, or type of training considered sufficient for all students and fellows. However given the circumstances in which misbehavior and misconduct have occurred in the past, ORI recommends nine topics be covered in some manner by all RCR training programs. The cases used in the GRAD713–716 course sequence cover all of these concepts.

1.	Rules of data acquisition, management, sharing and ownership
2.	Guarding against conflicts of interest and commitment
3.	Protection of human subjects
4.	Ensuring the welfare of animals used in research
5.	Research misconduct: fabrication, falsification, plagiarism
6.	Acceptable publication practices and responsibilities of authorship
7.	Responsibilities of mentors and their trainees
8.	Responsibilities when conducting peer reviews
9.	Responsibilities towards scientific collaborators

At present the Council of Graduate Schools (CGS) is urging policy makers and leaders in all disciplines that conduct federally funded independent research (including the social sciences, humanities, and the arts) to develop standards for responsible conduct of research for their fields, and to ensure that these standards are taught to all students and trainees in their discipline. 


What Does ORI Define As Inappropriate Behavior For Scientists?
ORI recognizes two types of inappropriate actions, which are defined below. Importantly, these do not include honest errors or differences of scientific opinion.

Misconduct 
     These are the incidents that make national headlines. Three behaviors fall under the heading of misconduct and are often abbreviated FFP; they are:
o	Fabrication–making up data or results and recording or reporting them
o	Falsification–manipulating research materials, equipment, or processes, or changing or omitting data or results such that the research is not accurately represented in the research record.
o	Plagiarism–appropriation of another person's ideas, processes, results, or words without giving appropriate credit.

Misbehavior 
     These are sometimes called questionable research practices (abbreviated QRP). Misbehavior is less likely to make the news, but is just as corrosive to the research enterprise. Here are some examples (the list is not exhaustive).
o	Failing to properly record data
o	Failing to retain records to support published data
o	Improper or insufficient protection of sensitive data or private information
o	Giving or denying authorships improperly
o	Misrepresenting speculation as fact
o	Refusing to grant reasonable requests for access to reagents created using public funds
o	Using inappropriate statistical methods
o	Providing inadequate supervision to subordinates, or exploiting them for personal or professional gain

ORI and other federal agencies view misbehavior and misconduct as theft; time has been stolen from collaborators, reviewers, and subordinates, and money has been stolen from the taxpayers and other investigators who acted honestly. Most accusations of misconduct and misbehavior are made by individuals working in the lab of the offending scientist, or by their collaborators. Cases must be investigated by the institution where the event occurred; failure to investigate is a sanctionable offense. Federal authorities acting on behalf of the funding agency may simultaneously investigate allegations as well. ORI requires evidence of willful intent to deceive before they will find an investigator guilty of misconduct/FFP. However, acts of plagiarism or falsification that do not rise to the level of misconduct can still be prosecuted as misbehavior/QRP violations.

Penalties for being found guilty of misbehavior and misconduct vary by institution, severity of the infraction, and extenuating circumstances. Federal penalties are severe; investigators found guilty of a single act of willful plagiarism can be barred from receiving public funds for 1–3 years. For more serious misconduct, a scientist may be banned from receiving federal funds for life. All federal findings of misbehavior/QRP or misconduct/FFP are published in the public record, and many foundations and private granting agencies refuse to award grants to censured scientists. 

A 2008 study (Redman and Merz, 2008) determined that only 43% of the academic scientists who had been formally censured by ORI between 1994 and 2001 were still employed in academia. Overall, 51% continued to publish an average of 1 paper per year. These numbers do not reflect any institutional sanctions or fines that were levied. The message is clear: willful misconduct is very likely to end a professional career.
 
Part  4: Learning Objectives and Structure of the Curriculum

Curriculum Philosophy

Problem-Based Learning 
The course sequence uses case scenarios presented in a problem-based learning (PBL) format combined with self-directed learning. PBL is an adult active learning method that asks learners to solve authentic, "real world" problems. The cases introduce cultural-specific rules and regulations, highlight scientific professional obligations, and explore ethical underpinnings, such as the points of ethical conflict and the principles, obligations, and consequences of a chosen course of action. The majority of medical schools in the United States make at least some use of the PBL approach (Daggett and Houston 1998). The Wake Forest University School of Medicine began PBL as a pilot project in 1987 and now has over two decades of experience in using the method to teach basic biomedical sciences.

Students work in small groups of 5-8 and each student is encouraged to articulate his/her own understanding of the problem(s) in each case, identify what information is fact-based, and start the process of determining what additional information is needed to work towards a resolution. The use of the small group promotes collaboration with peers and fosters development of effective teamwork skills (Lambros 2004).

Each case is explored during 2, two-hour sessions occurring 5-7 days apart.  At Session One, the case scenario is introduced and the group collaborates to identify key learning issues.  Each student works individually on the identified learning issues between the two sessions (self-directed learning).  At Session Two, the students use their newly acquired knowledge to explore in more depth issues introduced by the case and to further develop effective teamwork 


Self-Directed Learning 
Each student is expected to work independently on the learning issues arising from Session One. The goal is for students to develop self-directed learning skills, such as finding appropriate resources, problem solving, and formulating well-reasoned justifications for decisions. Students are required to document their self-directed learning by turning in concise written assignments. Session Two allows students to use the knowledge acquired during their self-directed learning activities.


Moral Reflection 
Cases are also constructed to promote moral reflection.  Four types of moral reflection are stimulated (though not necessarily all in any one case): moral sensitivity, moral reasoning and judgment, moral motivation and commitment, and moral character and competence (Bebeau, Rest, & Narvaez 1999, Rest, Narvaez, Bebeau, & Thoma 1999). These were described in detail in Part 3, but are repeated here for convenience.
 
•	Moral sensitivity is the ability to see things from the perspective of others and to be aware of legal, institutional, and national concerns. 
o	Teaching strategies in this context include presenting situations where the ethical issues have not been predigested or interpreted.  The students will need to be aware of nuances in the case scenarios and sort through relevant and irrelevant information in order to focus on pertinent research customs, rules, regulations, and laws.  One tact to highlight moral sensitivity is asking the students to consider something from another’s point of view. The goal is to promote sensitivity to ethical issues that are likely to arise in research settings.  

•	Moral reasoning and judgment involves learning ways to weigh the principles, values, and consequences embedded in moral judgments. 
o	The teaching strategy here is to force a choice or decision to assure eliciting reasoning rather than problem solving with several possible solutions.  Students will be prompted to defend their choices by supplying the criteria for their judgments. The course will use two approaches or methods for developing moral reasoning. Both of these methods will be explained in more detail in the facilitator guides for specific cases.
o	The first approach is “Developing a Well-Reasoned Response to a Moral Problem in Scientific Research Ethics”(Bebeau, Pimple et al. 1995). It provides a framework to construct and evaluate reasoning processes in moral problem-solving.  The framework requires identifying the (a) issues and points of conflict, (b) interested parties, (c) consequences, and (d) obligations. 
o	The second form of moral reasoning (adapted from: Iserson, Ethical Issues in Clinical Emergency Medicine (1999) 17:283) is to pose three questions
	Impartiality Test: Would you be willing to have this action performed if you were in the other person’s place?
	Universalizability Test:  Would you be comfortable if all “scientists” with the same background and in the same circumstances act as you are proposing to do?
	Justifiability Test: Am I ready to state openly to my peers, superiors, or the public my reasons that I acted as I propose to do? 

•	Moral motivation and commitment aims to develop a sense of professional identity
o	Teaching strategies here will include asking students to explain what their obligations as scientists are and providing the students with exemplary examples. The goal is to instill a sense of personal identity that incorporates the norms and values of the science and engineering culture.

•	Moral character and competence reflects a focus on personal skills such as interpersonal interaction and problem solving. 
o	Teaching strategies include role playing exercises. The goal is to build competence in problem-solving and interpersonal skills.
 
Course Objectives

The primary objective is for students to identify discipline-specific issues, and broad professional norms and obligations that will help them practice science as ethically responsible professionals.  
Specific Objectives include: 
•	Acquire skills to recognize ethical issues in the practice of science
•	Identify professional role obligations of scientists; such as graduate students, postdoctoral fellows, principal investigators and technicians
•	Identify norms for the responsible conduct of scientific research, such as data acquisition, management, sharing and ownership, publication practices, and responsible authorship
•	Develop sound moral reasoning to address ethical issues in the practice of science, such as identifying the points of ethical conflict, the principles, obligations, and consequences of a chosen course of action.
•	Develop skills for effective group work, such as clear communication, facilitating other group members to contribute, focusing on key concepts, moving discussion forward, and constructively critiquing others’ concepts 
•	Develop self-directed learning skills, such as increasing their ability to identify key learning issues in a situation, seek out and acquire new content knowledge, identify appropriate resources and apply their knowledge in ways that help them resolve those learning issues. 
In addition to these process objectives, there are specific factual content objectives embedded in each of the cases. These are described in the Facilitator Notes attached to each case.


 

Some Final Advice

The students in your small group do not work directly with you in a lab or clinical setting. However, they are developing professionals who look to you now as the model for their future behavior as members of the scientific community. The skills students will gain through this course experience will help them become ethically responsible scientists, and recognize and handle professional moral dilemmas effectively. In a very real way, this makes you one of their mentors. 

In this situation, being a good mentor means being an effective facilitator. Highly effective facilitators remain constantly aware of the primary process objectives of this course (which were discussed earlier). The most effective facilitators also have the highest functioning groups. These are the groups that are deeply engaged in the process of learning. They demonstrate good content acquisition skills, seek to understand relevant concepts, assist each other’s learning, and try to be highly effective communicators. As their facilitator, make a consistent effort to ensure that all of your small group members build these skills.

Be patient, but proactive. The PBL format has been thoroughly validated, and works extremely well. However, it takes time. Groups progress at different rates. Experienced facilitators can tell you about groups that came together almost instantly, while others took much longer. As long as the group functions well, its members will make progress towards the course goals. 

If your group really is not functioning well, do not just chalk it up to “a bad group.” You are responsible for taking active steps to correct the situation. At the end of cases, ask your student group what is not working, and how they propose to correct it. Ask to observe another group while it is in session. Discuss the problem with other facilitators. Seek advice from members of the Advisory Committee that designed this course. There are solutions to most group problems, but you as the facilitator must make the effort to find and implement them.
 
